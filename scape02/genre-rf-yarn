#!/bin/bash

export HADOOP_CONF_DIR=/etc/hadoop/conf
export YARN_CONF_DIR=$HADOOP_CONF_DIR

_now=$(date +"%Y-%m-%d_%H-%M-%S")
_output_stderr_dir="output-stderr"
_output_stdout_dir="output-stdout"
_jar_dir="jar"
_conf_dir="conf-single"

# command line flag --num-executors equals config property spark.executor.instances
# command line flag --executor-memory equals config property spark.executor.memory
# command line flag --executor-cores equals config property spark.executor.cores

_exec_inst="3" # number of executors
_exec_cores="1" # number of CPU cores per executor
_exec_mem="5G" # Java head size of each executor

(/opt/spark-2.1/bin/spark-submit \
  --jars $_jar_dir/config-1.3.1.jar,$_jar_dir/scallop_2.11-2.1.1.jar,$_jar_dir/spark-measure_2.11-0.1-SNAPSHOT.jar\
  --conf "spark.executor.instances=$_exec_inst"\
  --conf "spark.executor.cores=$_exec_cores"\
  --conf "spark.executor.memory=$_exec_mem"\
  --properties-file spark-submit-yarn.conf\
  --class "GenreRandomForestApp" $_jar_dir/machine-learning_2.11-1.0.jar\
  --config $_conf_dir/genre-randomForest.conf | \
    tee $_output_stdout_dir/$_now-exec-$_num_exec-cores-$_exec_cores-mem-$_exec_mem-stdout.log) 3>&1 1>&2 2>&3 | \
    tee $_output_stderr_dir/$_now-exec-$_num_exec-cores-$_exec_cores-mem-$_exec_mem-stderr.log 

//   --deploy-mode client\

